#!/bin/bash
# bulk_download_to_s3_parallel.sh
# å¹¶è¡Œæ‰¹é‡ä¸‹è½½ - ä» JAXA FTP æµå¼ä¸Šä¼ åˆ° S3
# æ”¯æŒå¤šçº¿ç¨‹ä¸‹è½½ï¼Œæ˜¾è‘—æå‡ä¸‹è½½é€Ÿåº¦

# S3 é…ç½®
S3_BUCKET="weather-ai-models-de08370c"
SATELLITE_PREFIX="satellite"
ARCHIVED_PREFIX="archived/satellite"  # å·²å¤„ç†çš„æ•°æ®å½’æ¡£ä½ç½®
GOVDATA_PREFIX="govdata"
MIN_FILES_PER_DAY=50  # æ¯å¤©æœ€å°‘æ–‡ä»¶æ•°ï¼Œä½äºæ­¤å€¼ä¸æ ‡è®°ä¸ºå®Œæˆ

# å¹¶è¡Œé…ç½®
PARALLEL_JOBS="${PARALLEL_JOBS:-4}"  # é»˜è®¤ 4 ä¸ªå¹¶è¡Œä¸‹è½½

# JAXA å‡­è¯
JAXA_USER="${JAXA_USER:-}"
JAXA_PASS="${JAXA_PASS:-}"

# æ—¥æœŸèŒƒå›´å‚æ•°
START_DATE="${1:-2025-10-01}"
END_DATE="${2:-2026-01-27}"

# æ—¥å¿—æ–‡ä»¶
LOG_FILE="download_parallel.log"
PROGRESS_FILE="/tmp/download_progress.txt"

if [ -z "$JAXA_USER" ] || [ -z "$JAXA_PASS" ]; then
    echo "âŒ è¯·è®¾ç½® JAXA_USER å’Œ JAXA_PASS ç¯å¢ƒå˜é‡"
    exit 1
fi

echo "============================================"
echo "ğŸ“¥ å¹¶è¡Œæ‰¹é‡ä¸‹è½½åˆ° S3"
echo "   æ—¥æœŸèŒƒå›´: $START_DATE è‡³ $END_DATE"
echo "   S3 å­˜å‚¨æ¡¶: s3://$S3_BUCKET/"
echo "   å¹¶è¡Œæ•°: $PARALLEL_JOBS"
echo "   æ—¶é—´: $(date)"
echo "============================================"

# è®¡ç®—æ€»å¤©æ•°
start_ts=$(date -d "$START_DATE" "+%s" 2>/dev/null || date -j -f "%Y-%m-%d" "$START_DATE" "+%s")
end_ts=$(date -d "$END_DATE" "+%s" 2>/dev/null || date -j -f "%Y-%m-%d" "$END_DATE" "+%s")
total_days=$(( (end_ts - start_ts) / 86400 + 1 ))
echo "   æ€»å¤©æ•°: $total_days"

# å•æ–‡ä»¶ä¸‹è½½å‡½æ•°
download_single_file() {
    local file="$1"
    local remote_path="$2"
    local date_fmt="$3"
    local s3_key="$SATELLITE_PREFIX/$date_fmt/$file"
    
    # æ£€æŸ¥ S3 æ˜¯å¦å·²å­˜åœ¨
    if aws s3 ls "s3://$S3_BUCKET/$s3_key" > /dev/null 2>&1; then
        echo "   â­ï¸ $file (å·²å­˜åœ¨)"
        return 0
    fi
    
    # æµå¼ä¸‹è½½å¹¶ä¸Šä¼ åˆ° S3
    if curl -s --ftp-ssl --user "$JAXA_USER:$JAXA_PASS" \
        "ftp://ftp.ptree.jaxa.jp$remote_path/$file" | \
        aws s3 cp - "s3://$S3_BUCKET/$s3_key" --quiet 2>/dev/null; then
        echo "   âœ… $file"
        return 0
    else
        echo "   âŒ $file"
        return 1
    fi
}

export -f download_single_file
export S3_BUCKET SATELLITE_PREFIX JAXA_USER JAXA_PASS

# ç»Ÿè®¡
downloaded_files=0
skipped_files=0

# æ—¥æœŸå¾ªç¯
current="$START_DATE"
day_count=0

while [[ "$current" < "$END_DATE" ]] || [[ "$current" == "$END_DATE" ]]; do
    ((day_count++))
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    year_month=$(date -d "$current" "+%Y%m" 2>/dev/null || date -j -f "%Y-%m-%d" "$current" "+%Y%m")
    day=$(date -d "$current" "+%d" 2>/dev/null || date -j -f "%Y-%m-%d" "$current" "+%d")
    date_fmt=$(echo "$current" | tr -d '-')
    
    echo ""
    echo "ğŸ“… [$day_count/$total_days] å¤„ç†: $current"
    
    # æ£€æŸ¥æ˜¯å¦å·²å®Œæˆï¼ˆåŒæ—¶æ£€æŸ¥ satellite/ å’Œ archived/satellite/ï¼‰
    if aws s3 ls "s3://$S3_BUCKET/$SATELLITE_PREFIX/$date_fmt/.complete" > /dev/null 2>&1; then
        echo "   â­ï¸ æ—¥æœŸå·²å®Œæˆï¼ˆsatellite/ï¼‰ï¼Œè·³è¿‡"
        current=$(date -d "$current + 1 day" "+%Y-%m-%d" 2>/dev/null || date -j -v+1d -f "%Y-%m-%d" "$current" "+%Y-%m-%d")
        continue
    fi
    
    # æ£€æŸ¥æ˜¯å¦åœ¨å½’æ¡£æ–‡ä»¶å¤¹ä¸­
    if aws s3 ls "s3://$S3_BUCKET/$ARCHIVED_PREFIX/$date_fmt/" > /dev/null 2>&1; then
        archived_count=$(aws s3 ls "s3://$S3_BUCKET/$ARCHIVED_PREFIX/$date_fmt/" 2>/dev/null | grep -c ".nc" || echo "0")
        if [ "$archived_count" -ge "$MIN_FILES_PER_DAY" ]; then
            echo "   â­ï¸ æ—¥æœŸå·²å½’æ¡£ï¼ˆarchived/ï¼Œ$archived_count æ–‡ä»¶ï¼‰ï¼Œè·³è¿‡"
            current=$(date -d "$current + 1 day" "+%Y-%m-%d" 2>/dev/null || date -j -v+1d -f "%Y-%m-%d" "$current" "+%Y-%m-%d")
            continue
        fi
    fi
    
    remote_path="/jma/netcdf/$year_month/$day"
    
    # è·å–æ–‡ä»¶åˆ—è¡¨
    files=$(curl -s --ftp-ssl -l --user "$JAXA_USER:$JAXA_PASS" "ftp://ftp.ptree.jaxa.jp$remote_path/" 2>/dev/null || echo "")
    
    if [ -z "$files" ]; then
        echo "   âš ï¸ æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨ï¼Œè·³è¿‡"
        current=$(date -d "$current + 1 day" "+%Y-%m-%d" 2>/dev/null || date -j -v+1d -f "%Y-%m-%d" "$current" "+%Y-%m-%d")
        continue
    fi
    
    # æ™ºèƒ½æ–‡ä»¶é€‰æ‹©ï¼šä¼˜å…ˆ 07001_06001ï¼Œfallback åˆ° 06001_06001
    # æ–‡ä»¶åæ ¼å¼: NC_H0[89]_YYYYMMDD_HHMM_R21_FLDK.0X001_06001.nc
    primary_files=$(echo "$files" | grep -E "^NC_H0[89]_.*_R21_FLDK\.07001_06001\.nc$" || echo "")
    fallback_files=$(echo "$files" | grep -E "^NC_H0[89]_.*_R21_FLDK\.06001_06001\.nc$" || echo "")
    
    # æå–æ—¶é—´æˆ³å¹¶é€‰æ‹©æ–‡ä»¶
    target_files=""
    # ä» primary æ–‡ä»¶ä¸­è·å–æ‰€æœ‰æ—¶é—´æˆ³
    primary_timestamps=$(echo "$primary_files" | sed -n 's/NC_H0[89]_\([0-9]*_[0-9]*\)_.*/\1/p' | sort -u)
    fallback_timestamps=$(echo "$fallback_files" | sed -n 's/NC_H0[89]_\([0-9]*_[0-9]*\)_.*/\1/p' | sort -u)
    
    # å¯¹æ¯ä¸ª primary æ—¶é—´æˆ³ï¼Œåªä¿ç•™ 07001 æ–‡ä»¶
    for ts in $primary_timestamps; do
        file=$(echo "$primary_files" | grep "NC_H0[89]_${ts}_" | head -1)
        if [ -n "$file" ]; then
            target_files="$target_files$file"$'\n'
        fi
    done
    
    # å¯¹äº primary ä¸­æ²¡æœ‰çš„æ—¶é—´æˆ³ï¼Œä½¿ç”¨ fallback
    for ts in $fallback_timestamps; do
        if ! echo "$primary_timestamps" | grep -q "^${ts}$"; then
            file=$(echo "$fallback_files" | grep "NC_H0[89]_${ts}_" | head -1)
            if [ -n "$file" ]; then
                target_files="$target_files$file"$'\n'
                echo "   â„¹ï¸ ä½¿ç”¨å¤‡é€‰: $file"
            fi
        fi
    done
    
    # å»é™¤ç©ºè¡Œ
    target_files=$(echo "$target_files" | grep -v "^$" || echo "")
    file_count=$(echo "$target_files" | grep -c "." || echo "0")
    
    echo "   ğŸ“ æ‰¾åˆ° $file_count ä¸ªå«æ˜Ÿæ–‡ä»¶ (ä¼˜å…ˆ 07001ï¼Œfallback 06001)"
    echo "   ğŸš€ å«æ˜Ÿæ•°æ®å’Œæ”¿åºœæ•°æ®å¹¶è¡Œä¸‹è½½..."
    
    # å®šä¹‰æ”¿åºœæ•°æ®ä¸‹è½½å‡½æ•°
    download_govdata() {
        local current_date="$1"
        for api in "rainfall" "temperature" "humidity" "pm25"; do
            s3_key="$GOVDATA_PREFIX/${api}_${current_date}.json"
            
            if aws s3 ls "s3://$S3_BUCKET/$s3_key" > /dev/null 2>&1; then
                continue
            fi
            
            case $api in
                rainfall) url="https://api.data.gov.sg/v1/environment/rainfall" ;;
                temperature) url="https://api.data.gov.sg/v1/environment/air-temperature" ;;
                humidity) url="https://api.data.gov.sg/v1/environment/relative-humidity" ;;
                pm25) url="https://api.data.gov.sg/v1/environment/pm25" ;;
            esac
            
            curl -s "$url?date=$current_date" | aws s3 cp - "s3://$S3_BUCKET/$s3_key" --quiet 2>/dev/null || true
        done
        echo "   âœ… æ”¿åºœæ•°æ®å®Œæˆ: $current_date"
    }
    export -f download_govdata
    export S3_BUCKET GOVDATA_PREFIX
    
    # å¹¶è¡Œæ‰§è¡Œï¼šå«æ˜Ÿæ•°æ® + æ”¿åºœæ•°æ®
    (
        # ä»»åŠ¡1ï¼šå¹¶è¡Œä¸‹è½½å«æ˜Ÿæ–‡ä»¶
        echo "$target_files" | xargs -P "$PARALLEL_JOBS" -I {} bash -c \
            "download_single_file '{}' '$remote_path' '$date_fmt'"
        echo "   âœ… å«æ˜Ÿæ•°æ®å®Œæˆ: $current"
    ) &
    satellite_pid=$!
    
    (
        # ä»»åŠ¡2ï¼šä¸‹è½½æ”¿åºœæ•°æ®
        download_govdata "$current"
    ) &
    govdata_pid=$!
    
    # ç­‰å¾…ä¸¤ä¸ªä»»åŠ¡éƒ½å®Œæˆ
    wait $satellite_pid
    wait $govdata_pid
    
    # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶æ•°é‡
    actual_count=$(aws s3 ls "s3://$S3_BUCKET/$SATELLITE_PREFIX/$date_fmt/" 2>/dev/null | grep -c ".nc" || echo "0")
    
    if [ "$actual_count" -ge "$MIN_FILES_PER_DAY" ]; then
        # åˆ›å»ºå®Œæˆæ ‡è®°ï¼ˆåªæœ‰è¾¾åˆ°æœ€ä½æ–‡ä»¶æ•°æ‰æ ‡è®°ï¼‰
        echo "$current" | aws s3 cp - "s3://$S3_BUCKET/$SATELLITE_PREFIX/$date_fmt/.complete" --quiet
        echo "   âœ… æ—¥æœŸå®Œæˆ: $current ($actual_count æ–‡ä»¶)"
    else
        echo "   âš ï¸ æ—¥æœŸæœªå®Œæˆ: $current (åªæœ‰ $actual_count æ–‡ä»¶ï¼Œéœ€è¦ >= $MIN_FILES_PER_DAY)"
    fi
    
    # ä¸‹ä¸€å¤©
    current=$(date -d "$current + 1 day" "+%Y-%m-%d" 2>/dev/null || date -j -v+1d -f "%Y-%m-%d" "$current" "+%Y-%m-%d")
done

echo ""
echo "============================================"
echo "ğŸ“Š ä¸‹è½½å®Œæˆ"
echo "   å®Œæˆæ—¶é—´: $(date)"
echo "============================================"
