#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–è®­ç»ƒæµç¨‹ä¸»ç¼–æ’è„šæœ¬
åè°ƒæ•°æ®è·å–ã€è®­ç»ƒã€è¯„ä¼°å’Œé€šçŸ¥çš„å®Œæ•´æµç¨‹
"""
import os
import sys
import json
import logging
import subprocess
import time
from datetime import datetime, timedelta, date
from pathlib import Path
import traceback

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from notification import send_training_success_email, send_training_failure_email
from generate_report import generate_html_report
from training_history import add_training_record, get_training_stats

# æ—¥å¿—é…ç½®
LOG_DIR = "training_logs"
os.makedirs(LOG_DIR, exist_ok=True)

log_file = os.path.join(LOG_DIR, f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# é…ç½®
MAX_RETRIES = 2
STATE_FILE = "training_state.json"


class TrainingPipeline:
    """è‡ªåŠ¨åŒ–è®­ç»ƒæµç¨‹ç®¡ç†å™¨"""
    
    def __init__(self):
        self.start_time = datetime.now()
        self.state = self.load_state()
        self.current_step = None
        self.retry_count = 0
        
    def load_state(self):
        """åŠ è½½ä¸Šæ¬¡è®­ç»ƒçŠ¶æ€"""
        if os.path.exists(STATE_FILE):
            try:
                with open(STATE_FILE, 'r') as f:
                    return json.load(f)
            except:
                return {}
        return {}
    
    def save_state(self):
        """ä¿å­˜å½“å‰çŠ¶æ€"""
        with open(STATE_FILE, 'w') as f:
            json.dump(self.state, f, indent=2, default=str)
    
    def get_last_training_date(self):
        """è·å–ä¸Šæ¬¡è®­ç»ƒçš„ç»“æŸæ—¥æœŸ"""
        if 'last_training_end_date' in self.state:
            return datetime.strptime(self.state['last_training_end_date'], '%Y-%m-%d').date()
        # é»˜è®¤ä»20å¤©å‰å¼€å§‹ï¼ˆå¦‚æœæ˜¯é¦–æ¬¡è®­ç»ƒï¼‰
        return date.today() - timedelta(days=20)
    
    def run_command(self, cmd, step_name, timeout=3600):
        """
        è¿è¡Œshellå‘½ä»¤
        
        Args:
            cmd: å‘½ä»¤åˆ—è¡¨æˆ–å­—ç¬¦ä¸²
            step_name: æ­¥éª¤åç§°
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        logger.info(f"{'='*60}")
        logger.info(f"å¼€å§‹æ‰§è¡Œ: {step_name}")
        logger.info(f"å‘½ä»¤: {' '.join(cmd) if isinstance(cmd, list) else cmd}")
        logger.info(f"{'='*60}")
        
        self.current_step = step_name
        
        try:
            if isinstance(cmd, str):
                cmd = cmd.split()
            
            # ğŸ†• æ·»åŠ ç¯å¢ƒå˜é‡å¼ºåˆ¶æ— ç¼“å†²è¾“å‡º
            env = os.environ.copy()
            env['PYTHONUNBUFFERED'] = '1'
            
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=timeout,
                check=True,
                env=env  # ğŸ†• ä¼ é€’ç¯å¢ƒå˜é‡
            )
            
            logger.info(f"âœ… {step_name} å®Œæˆ")
            if result.stdout:
                logger.info(f"è¾“å‡º:\n{result.stdout}")
            
            return True
            
        except subprocess.TimeoutExpired:
            logger.error(f"âŒ {step_name} è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰")
            return False
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ {step_name} å¤±è´¥")
            logger.error(f"è¿”å›ç : {e.returncode}")
            if e.stdout:
                logger.error(f"æ ‡å‡†è¾“å‡º:\n{e.stdout}")
            if e.stderr:
                logger.error(f"é”™è¯¯è¾“å‡º:\n{e.stderr}")
            return False
        except Exception as e:
            logger.error(f"âŒ {step_name} å¼‚å¸¸: {e}")
            logger.error(traceback.format_exc())
            return False
    
    def step_1_download_satellite_data(self):
        """æ­¥éª¤1: ä¸‹è½½å«æ˜Ÿæ•°æ®"""
        logger.info("\nğŸ“¡ æ­¥éª¤ 1/5: ä¸‹è½½å«æ˜Ÿæ•°æ®")
        
        # ä¸‹è½½æœ€è¿‘24å°æ—¶çš„æ•°æ®
        cmd = [
            "python3", "download_jaxa_data.py",
            "--mode", "batch",
            "--hours", "24"
        ]
        
        return self.run_command(cmd, "ä¸‹è½½å«æ˜Ÿæ•°æ®", timeout=1800)
    
    def step_2_download_sensor_data(self):
        """æ­¥éª¤2: ä¸‹è½½ä¼ æ„Ÿå™¨æ•°æ®ï¼ˆå¢é‡ï¼‰"""
        logger.info("\nğŸŒ¡ï¸ æ­¥éª¤ 2/5: ä¸‹è½½ä¼ æ„Ÿå™¨æ•°æ®")
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        last_date = self.get_last_training_date()
        start_date = last_date + timedelta(days=1)
        end_date = date.today()
        
        logger.info(f"æ•°æ®èŒƒå›´: {start_date} è‡³ {end_date}")
        
        # æ›´æ–° fetch_and_process_gov_data.py çš„é…ç½®
        # è¿™é‡Œæˆ‘ä»¬éœ€è¦ä¿®æ”¹è„šæœ¬ä»¥æ”¯æŒå‘½ä»¤è¡Œå‚æ•°ï¼Œæˆ–è€…ç›´æ¥ä¿®æ”¹é…ç½®
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¯å¢ƒå˜é‡ä¼ é€’æ—¥æœŸ
        
        env = os.environ.copy()
        env['FETCH_START_DATE'] = start_date.isoformat()
        env['FETCH_END_DATE'] = end_date.isoformat()
        
        cmd = ["python3", "fetch_and_process_gov_data.py"]
        
        success = self.run_command(cmd, "ä¸‹è½½ä¼ æ„Ÿå™¨æ•°æ®", timeout=1800)
        
        if success:
            # æ›´æ–°çŠ¶æ€
            self.state['last_training_end_date'] = end_date.isoformat()
            self.save_state()
        
        return success
    
    def step_3_preprocess_satellite_images(self):
        """æ­¥éª¤3: é¢„å¤„ç†å«æ˜Ÿå›¾åƒ"""
        logger.info("\nğŸ–¼ï¸ æ­¥éª¤ 3/5: é¢„å¤„ç†å«æ˜Ÿå›¾åƒ")
        
        cmd = ["python3", "preprocess_images.py"]
        
        return self.run_command(cmd, "é¢„å¤„ç†å«æ˜Ÿå›¾åƒ", timeout=1800)
    
    def step_4_train_model(self):
        """æ­¥éª¤4: è®­ç»ƒæ¨¡å‹"""
        logger.info("\nğŸ§  æ­¥éª¤ 4/5: è®­ç»ƒæ¨¡å‹")
        
        cmd = ["python3", "train.py"]
        
        return self.run_command(cmd, "è®­ç»ƒæ¨¡å‹", timeout=3600)
    
    def step_5_evaluate_model(self):
        """æ­¥éª¤5: è¯„ä¼°æ¨¡å‹"""
        logger.info("\nğŸ“Š æ­¥éª¤ 5/5: è¯„ä¼°æ¨¡å‹")
        
        cmd = ["python3", "evaluate.py"]
        
        return self.run_command(cmd, "è¯„ä¼°æ¨¡å‹", timeout=600)
    
    def collect_metrics(self):
        """æ”¶é›†è¯„ä¼°æŒ‡æ ‡"""
        logger.info("\nğŸ“ˆ æ”¶é›†è¯„ä¼°æŒ‡æ ‡...")
        
        # ä»evaluate.pyç”Ÿæˆçš„JSONæ–‡ä»¶è¯»å–æŒ‡æ ‡
        results_file = "evaluation_results.json"
        
        if os.path.exists(results_file):
            try:
                with open(results_file, 'r') as f:
                    metrics = json.load(f)
                logger.info(f"å·²ä» {results_file} åŠ è½½è¯„ä¼°æŒ‡æ ‡")
                return metrics
            except Exception as e:
                logger.warning(f"è¯»å–è¯„ä¼°ç»“æœå¤±è´¥: {e}")
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›é»˜è®¤å€¼
        logger.warning("è¯„ä¼°ç»“æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        return {
            'mae': 0.0,
            'rmse': 0.0,
            'accuracy': 0.0,
            'threshold': 0.1,
            'num_samples': 0
        }
    
    def collect_data_info(self):
        """æ”¶é›†æ•°æ®ä¿¡æ¯"""
        logger.info("\nğŸ“ æ”¶é›†æ•°æ®ä¿¡æ¯...")
        
        # ç»Ÿè®¡å«æ˜Ÿæ–‡ä»¶æ•°é‡
        sat_dir = "satellite_data"
        sat_files = len([f for f in os.listdir(sat_dir) if f.endswith('.nc')]) if os.path.exists(sat_dir) else 0
        
        # ç»Ÿè®¡ä¼ æ„Ÿå™¨è®°å½•æ•°
        import pandas as pd
        csv_path = "real_sensor_data.csv"
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path)
            sensor_records = len(df)
            num_sensors = df['sensor_id'].nunique() if 'sensor_id' in df.columns else 0
            date_range = f"{df['timestamp'].min()} è‡³ {df['timestamp'].max()}" if 'timestamp' in df.columns else "N/A"
        else:
            sensor_records = 0
            num_sensors = 0
            date_range = "N/A"
        
        return {
            'satellite_files': sat_files,
            'sensor_records': sensor_records,
            'num_sensors': num_sensors,
            'date_range': date_range
        }
    
    def collect_training_info(self):
        """æ”¶é›†è®­ç»ƒä¿¡æ¯"""
        duration = datetime.now() - self.start_time
        minutes = int(duration.total_seconds() // 60)
        seconds = int(duration.total_seconds() % 60)
        
        # ğŸ†• ä»ç¯å¢ƒå˜é‡è¯»å–å®é™…é…ç½®
        epochs_initial = int(os.environ.get('EPOCHS_INITIAL', 30))
        epochs_incremental = int(os.environ.get('EPOCHS_INCREMENTAL', 5))
        
        # åˆ¤æ–­æ˜¯å¦å­˜åœ¨æ¨¡å‹æ–‡ä»¶æ¥ç¡®å®šä½¿ç”¨å“ªä¸ªepochså€¼
        model_exists = os.path.exists("weather_fusion_model.pth")
        actual_epochs = epochs_incremental if model_exists else epochs_initial
        
        return {
            'epochs': actual_epochs,
            'epochs_mode': 'å¢é‡è®­ç»ƒ' if model_exists else 'é¦–æ¬¡è®­ç»ƒ',
            'batch_size': 4,
            'learning_rate': 0.001,
            'duration': f"{minutes}åˆ†{seconds}ç§’",
            'best_loss': 0.0,  # ä»è®­ç»ƒæ—¥å¿—è¯»å–
            'device': 'Auto'
        }
    
    def generate_and_send_report(self, success=True, error_message=None):
        """ç”Ÿæˆå¹¶å‘é€æŠ¥å‘Š"""
        logger.info("\nğŸ“§ ç”Ÿæˆå¹¶å‘é€æŠ¥å‘Š...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if success:
            # æ”¶é›†æ‰€æœ‰ä¿¡æ¯
            metrics = self.collect_metrics()
            data_info = self.collect_data_info()
            training_info = self.collect_training_info()
            
            # ç”ŸæˆæŠ¥å‘Š
            report_path = f"training_reports/report_{timestamp}.html"
            report_path = generate_html_report(metrics, training_info, data_info, report_path)
            
            # å‘é€æˆåŠŸé‚®ä»¶
            plot_path = "evaluation_plot.png"
            send_training_success_email(report_path, plot_path, metrics)
            
        else:
            # å‘é€å¤±è´¥é‚®ä»¶
            send_training_failure_email(
                error_message or "æœªçŸ¥é”™è¯¯",
                self.current_step or "æœªçŸ¥æ­¥éª¤",
                log_file
            )
    
    def run(self):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        logger.info("="*80)
        logger.info("ğŸš€ å¼€å§‹è‡ªåŠ¨åŒ–è®­ç»ƒæµç¨‹")
        logger.info(f"å¼€å§‹æ—¶é—´: {self.start_time}")
        logger.info("="*80)
        
        steps = [
            self.step_1_download_satellite_data,
            self.step_2_download_sensor_data,
            self.step_3_preprocess_satellite_images,
            self.step_4_train_model,
            self.step_5_evaluate_model
        ]
        
        for step_func in steps:
            success = False
            
            # é‡è¯•é€»è¾‘
            for attempt in range(MAX_RETRIES + 1):
                if attempt > 0:
                    logger.warning(f"ğŸ”„ é‡è¯• {attempt}/{MAX_RETRIES}...")
                    time.sleep(5)  # ç­‰å¾…5ç§’åé‡è¯•
                
                success = step_func()
                
                if success:
                    break
            
            if not success:
                error_msg = f"æ­¥éª¤å¤±è´¥ï¼ˆå·²é‡è¯•{MAX_RETRIES}æ¬¡ï¼‰: {step_func.__name__}"
                logger.error(f"\nâŒ {error_msg}")
                logger.error("æµç¨‹ä¸­æ­¢")
                
                # å‘é€å¤±è´¥é€šçŸ¥
                self.generate_and_send_report(success=False, error_message=error_msg)
                return False
        
        # æ‰€æœ‰æ­¥éª¤æˆåŠŸ
        end_time = datetime.now()
        duration = end_time - self.start_time
        logger.info("\n" + "="*80)
        logger.info("âœ… è®­ç»ƒæµç¨‹å®Œæˆï¼")
        logger.info(f"æ€»è€—æ—¶: {duration}")
        logger.info("="*80)
        
        # æ”¶é›†ä¿¡æ¯ç”¨äºå†å²è®°å½•
        metrics = self.collect_metrics()
        data_info = self.collect_data_info()
        training_info = self.collect_training_info()
        
        # è®°å½•è®­ç»ƒå†å²
        training_config = {
            'epochs': 30,
            'batch_size': 4,
            'learning_rate': 0.001
        }
        
        add_training_record(
            start_time=self.start_time,
            end_time=end_time,
            duration_seconds=duration.total_seconds(),
            metrics=metrics,
            data_info=data_info,
            training_config=training_config,
            success=True
        )
        
        logger.info("âœ… è®­ç»ƒå†å²å·²è®°å½•")
        
        # ç”Ÿæˆå¹¶å‘é€æˆåŠŸæŠ¥å‘Š
        self.generate_and_send_report(success=True)
        
        return True


def main():
    """ä¸»å‡½æ•°"""
    try:
        pipeline = TrainingPipeline()
        success = pipeline.run()
        sys.exit(0 if success else 1)
    except Exception as e:
        logger.error(f"âŒ æµç¨‹å¼‚å¸¸: {e}")
        logger.error(traceback.format_exc())
        
        # å‘é€å¤±è´¥é€šçŸ¥
        send_training_failure_email(
            str(e) + "\n\n" + traceback.format_exc(),
            "æµç¨‹å¼‚å¸¸",
            log_file
        )
        sys.exit(1)


if __name__ == "__main__":
    main()
